智能信贷业务辅助系统

一、项目目标

构建一个面向业务人员的智能辅助系统，通过 大模型 + RAG + 客户预测模块，提升业务人员对政策、系统功能和客户风险的理解与操作效率。
llm-apikey，保留本地部署的方式。

目标：

- 帮助业务人员快速查询政策与规则说明
- 提供信贷系统功能与操作指引
- 对客户历史数据进行解释性分析与趋势展示

二、实现方式

- 大模型（LLM qwen-max）
- RAG 系统（检索增强生成）
- 预测模型（客户贷款意向预测）

注意事项：需先执行script下预处理模块，请在config下配置数据库连接、es、llm-apikey、prompts等内容，具体参考项目下md，rerank默认关闭。

三、项目功能

1. 政策查询与风险提示
   基于公开政策和监管文件提供快速查询
   提供监管报送提示与操作参考
   注意：不参与、不替代任何审批或授信决策
2. 系统功能指导
   帮助业务人员熟悉信贷系统功能，减少误操作
   Demo 引入开发人员的设计文档或功能说明
   提供 操作流程指导 + 功能使用示例
3. 客户贷款意向预测能力（可选模块）
   基于模拟客户数据进行预测
   展示模型能力、趋势分析
   协助业务人员主动推荐产品（）
   可结合意图识别路由问题到 RAG 或预测模块
  
四、准备工作
数据准备：

| 数据类型    | 来源                                                            | 使用方式                                   |
| ------- | ------------------------------------------------------------- | -------------------------------------- |
| 政策文档    | 公开银行政策、监管文件（nfra.gov.cn / pbc.gov.cn / jrjgj.xinjiang.gov.cn） | OCR重组修复 → 解析为文本 → 切分 → RAG 向量库                   |
| 系统功能文档  | 模拟信贷系统功能说明                                                | 解析为文本 → 切分 → RAG 向量库                   |
| 客户数据    | Hugging Face (loan-prediction-dataset)                        | 用于预测模块演示，带客户经理字段                       |
| 预测标签/历史 | 模拟或生成                                                         | 用于训练 LightGBM/Transformer 模型，展示趋势和决策依据 |

注意事项：
 - 所有客户数据必须 模拟/脱敏，面试 Demo 不使用真实客户
 - 文档解析建议：Mineru 本地解析或 Python PDF/Word 库 → 文本切分
 - QA 对整理（可选）：从文档中抽取常见业务问题 → 对应答案 → 向量化，提升 RAG 检索精度

五、详细设计流程

1.整理文档
 - 政策文件、系统操作手册文档分域整理 √

2.文件清洗
 - OCR 修复多页图片，保证条款级连续性和可追溯性 √

3.Mineru 解析文档成 Markdown √

4.数据入库
 - 客户数据入本地数据库，Cursor 自动加 comments √

5.初步切分 QA 对
 - 按条款/章节/语义块切分，不使用 LLM
 - 使用 LLM 生成 QA 对（Q 为大模型生成，A 为政策或系统功能点） √

6.QA 对原子化
 - 每个 QA 对对应一个独立知识点，按域分类 √

7.Metadata 注入
  每条 QA 对增加以下信息：
  {
  "domain": "policy",
  "doc_type": "监管政策",
  "source": "国家金融监督管理总局",
  "region": "全国",
  "role": "客户经理",
  "status": "生效"
  } √

8.构建 QA 对索引并入 Elasticsearch √
 - 单个索引 {index_name}
 - 支持混合搜索（BM25 + 向量）

9.Query 改写、向量化，RAG 重排序，LLM 返回内容 √

10.大模型意图识别（CoT 思维链推理） √

11.功能串联
 - query → query 改写 → 意图识别 → Elasticsearch → LLM 总结返回内容 √

12.预测模型训练（可选）
 - LightGBM → 模拟数据训练 → 调参

13.界面搭建（Flask） √

切面：监控 token 消耗与时间

六、系统边界

- RAG：不存储敏感客户数据，仅提供政策与功能辅助
- 预测模块：仅模拟分析，不参与审批或授信
- 权限控制：模拟不同业务角色访问

七、系统提示词管理

- 所有提示词统一放在 config 文件中配置
- 后期可增加 PromptManager 类，支持动态加载、版本管理

八、QA 对说明

场景	QA条数建议	说明
政策查询	1 条/条款	一个问题 = 一个独立知识点
系统操作	1 条/功能	覆盖操作步骤与示例
客户预测	暂

九、Token & 时间监控

1.Token 监控示例
{
  "trace_id": "uuid",
  "module": "intent_router",
  "model": "gpt-4o-mini / qwen2.5",
  "prompt_tokens": 420,
  "completion_tokens": 98,
  "total_tokens": 518,
  "latency_ms": 820,
  "timestamp": "2025-01-10 14:32:10"
}

用户请求聚合示例

{
  "trace_id": "uuid",
  "user_query": "客户风险高不高？政策支持吗？",
  "steps": [
    {"module": "intent_router", "tokens": 518},
    {"module": "policy_rag_answer", "tokens": 1240},
    {"module": "prediction_explain", "tokens": 310}
  ],
  "total_tokens": 2068
}

2.时间监控

- 记录各步骤耗时：query改写 / 意图识别与路由 / RAG / 预测 / 重排序 / llm重组回答

十、缓存策略（待开发）

- Redis 缓存 query + query 改写
- 不直接缓存 LLM 返回，避免泄露预测敏感信息和过期数据

十一、权限逻辑

- 模拟客户经理身份 → 查询过滤
- 输入 → 意图识别 → 路由 → 输出 → 可视化展示

十二、query上下文记忆设计

总体分层L0-L4：

L0：单轮上下文（当前问题）

L1：会话级记忆（会话记录）

 - 每轮query都保存在ES，可审计
  示例：第一轮对话query（query后query改写前写入L1）
  {
    "session_id": "sess_001",             ## 对话id，用于 L1 / L2 关联
    "turn_id": "1",                       ## 对话轮次编号
    "role": "user",                       ## 对话角色（user / assistant）
    "content": "查询押品怎么创建",         ## 用户原始输入或助手输出
    "timestamp":"2026-01-05T14:01:00Z"    ## 时间戳
  }
  第一轮对话answer（最终llm生成后写入L1）
  {
    "session_id": "sess_001",               ## 对话id，用于 L1 / L2 关联
    "turn_id": 1,                           ## 对话轮次编号
    "role": "assistant",                    ## 对话角色（user / assistant）
    "content": "押品创建流程为：登录系统 → 进入押品模块 → 填写基本信息 → 提交审批。",     ## 用户原始输入或助手输出
    "timestamp": "2026-01-05T14:00:02Z"     ## 时间戳
  }
  第二轮对话query
  {
    "session_id": "sess_001",               ## 对话id，用于 L1 / L2 关联
    "turn_id": "2",                         ## 对话轮次编号
    "role": "user",                         ## 对话角色（user / assistant）
    "content": "那怎么入库呢",               ## 用户原始输入或助手输出
    "timestamp":"2026-01-05T14:05:00Z"      ## 时间戳
  }

L2：业务状态记忆（保持当前业务操作状态，支持连续查询、对象补全、模块路由。结构化、可继承、可覆盖的）
 - 结构化，用 JSON 字段记录各类状态，而不是文本,示例：{"business_object":"押品","operation_stage":"创建"}
 - 可继承，如果意图没变，当前轮 query 以继承上一轮L2信息,示例：Q2 没写对象 → 用上一轮 business_object 补全
 - 可覆盖，如果当前 query 确修改了对象或阶段，覆盖L2对应字段,示例：Q2 明确写“入库” → 更新 operation_stage
 - L2继承和覆盖使用规则：（规则 1：intent 不同 → 全量覆盖；规则 2：intent 相同 + 对象未显式出现 → 继承；规则 3：对象显式变化 → 覆盖；规则 4：阶段只能单向推进，例：创建 → 入库 → 审批）
 - 每轮query都保存在redis，可快速查询，生命周期同session
 - 每轮query都保存在ES，可审计

  示例：第一轮对话query
  {
    "session_id": "sess_001",               ## 对话id，用于 L1 / L2 关联
    "current_customer_id": null,            ## 当前讨论的客户ID，可为空
    "operation_chain":[                     ## 追踪多轮操作链，当用户问题包含多个意图时，要保存全部意图
      {
        "intent": "system_operation",           ## 本轮意图（policy / system / risk_analysis 等）
        "active_domain": ["system"], ## 当前可作用的业务域（policy、risk、system 等）
        "business_object": "押品",              ## 操作对象：押品
        "operation_stage": "创建",              ## 操作阶段：创建
        "last_action": "查询押品创建流程",       ## 上一步动作 / 说明阶段
        "last_update": "2026-01-05T14:00:02Z"   ## 更新时间
      }
    ]
  }

  第二轮对话query
  
  {
    "session_id": "sess_001",               ## 对话id，用于 L1 / L2 关联
    "current_customer_id": null,            ## 当前讨论的客户ID，可为空
    "operation_chain":[                     ## 追踪多轮操作链，当用户问题包含多个意图时，要保存全部意图
      {
        "intent": "system_operation",           ## 本轮意图（policy / system / risk_analysis 等）
        "active_domain": ["system"], ## 当前可作用的业务域（policy、risk、system 等）
        "business_object": "押品",              ## 操作对象：押品
        "operation_stage": "入库",              ## 操作阶段：创建
        "last_action": "查询押品入库流程",       ## 上一步动作 / 说明阶段
        "last_update": "2026-01-05T14:00:02Z"   ## 更新时间
      }
    ]
  }

L3：长期偏好记忆（用户行为习惯，暂未开发）

最终流程：
用户 query
  ↓
写入 L1（原始 query）
  ↓
（可选，暂不实现）读取 L1 历史
  ↓
query 改写 LLM  ← 只做改写
  ↓
【读取 L2】
  ↓
意图识别 + 关键实体抽取 LLM  ← 同一次调用就抽取 L2 所需字段
  ↓
更新 / 写入 L2（规则+继承，不用额外 LLM）
  ↓
路由 & ES 查询（用 L2 过滤 domain/object）
  ↓
LLM 重组答案
  ↓
写入 L1（助手回答）

十三、query历史记录查询（审计）
 - 页面增加查询历史对话功能，类似gpt、deepseek


问题：
1.对象补全
2.意图继承