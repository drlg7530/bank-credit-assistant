# Tokenç›‘æ§å’Œæ—¶é—´ç›‘æ§æ¨¡å—ä½¿ç”¨è¯´æ˜

## ğŸ“‹ åŠŸèƒ½è¯´æ˜

ç›‘æ§æ¨¡å—æä¾›äº†å®Œæ•´çš„Tokenç›‘æ§å’Œæ—¶é—´ç›‘æ§åŠŸèƒ½ï¼Œç¬¦åˆéœ€æ±‚æ–‡æ¡£ä¸­çš„è®¾è®¡è§„èŒƒã€‚

### ä¸»è¦åŠŸèƒ½

1. **å•æ¬¡LLMè°ƒç”¨ç›‘æ§**ï¼šè®°å½•æ¯æ¬¡LLMè°ƒç”¨çš„tokenä½¿ç”¨æƒ…å†µå’Œè€—æ—¶
2. **ç”¨æˆ·è¯·æ±‚çº§åˆ«èšåˆç›‘æ§**ï¼šå°†ä¸€æ¬¡ç”¨æˆ·è¯·æ±‚çš„å¤šæ¬¡è°ƒç”¨èšåˆèµ·æ¥
3. **æ—¶é—´ç›‘æ§**ï¼šç»Ÿè®¡ä¸åŒæ­¥éª¤çš„è€—æ—¶

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹å¼1ï¼šè‡ªåŠ¨ç›‘æ§ï¼ˆå·²é›†æˆåˆ°LLMè°ƒç”¨å‡½æ•°ï¼‰

LLMè°ƒç”¨å‡½æ•°å·²è‡ªåŠ¨é›†æˆç›‘æ§åŠŸèƒ½ï¼Œæ— éœ€é¢å¤–é…ç½®ï¼š

```python
from src.rag.query import call_llm

# è°ƒç”¨æ—¶ä¼šè‡ªåŠ¨è®°å½•ç›‘æ§ä¿¡æ¯
result = call_llm(
    prompt="ä½ çš„æç¤ºè¯",
    module="policy_rag_answer"  # æŒ‡å®šæ¨¡å—åç§°
)
```

### æ–¹å¼2ï¼šä½¿ç”¨è£…é¥°å™¨ç›‘æ§è‡ªå®šä¹‰å‡½æ•°

```python
from src.utils.monitor import monitor_llm_call

@monitor_llm_call(module="custom_module", model="qwen-plus")
def my_llm_function(prompt: str) -> str:
    # ä½ çš„LLMè°ƒç”¨ä»£ç 
    return response
```

### æ–¹å¼3ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç›‘æ§æ­¥éª¤

```python
from src.utils.monitor import monitor_step

with monitor_step("intent_router") as step:
    # æ‰§è¡Œæ„å›¾è¯†åˆ«
    result = classify_intent(question)
    step['result'] = result
```

### æ–¹å¼4ï¼šç”¨æˆ·è¯·æ±‚çº§åˆ«çš„èšåˆç›‘æ§

```python
from src.utils.monitor import RequestMonitor, get_monitor_manager

# åˆ›å»ºè¯·æ±‚ç›‘æ§å™¨
request_monitor = RequestMonitor(user_query="è¿™ä¸ªå®¢æˆ·é£é™©é«˜ä¸é«˜ï¼Ÿ")

# æ­¥éª¤1ï¼šæ„å›¾è¯†åˆ«
with monitor_step("intent_router", request_monitor.trace_id) as step1:
    intent_result = classify_intent(question)
    # ä»ç›‘æ§ç®¡ç†å™¨è·å–æœ€è¿‘çš„è°ƒç”¨è®°å½•
    recent_calls = get_monitor_manager().get_call_records(limit=1)
    if recent_calls:
        last_call = recent_calls[-1]
        request_monitor.add_step(
            module="intent_router",
            tokens=last_call['total_tokens'],
            latency_ms=last_call['latency_ms']
        )

# æ­¥éª¤2ï¼šRAGæŸ¥è¯¢
with monitor_step("policy_rag_answer", request_monitor.trace_id) as step2:
    answer = rag_query(query, domain='policy')
    recent_calls = get_monitor_manager().get_call_records(limit=1)
    if recent_calls:
        last_call = recent_calls[-1]
        request_monitor.add_step(
            module="policy_rag_answer",
            tokens=last_call['total_tokens'],
            latency_ms=last_call['latency_ms']
        )

# å®Œæˆè¯·æ±‚ç›‘æ§
request_record = request_monitor.finish(success=True)
print(f"æ€»Tokenæ•°: {request_record.total_tokens}")
print(f"æ€»è€—æ—¶: {request_record.total_latency_ms:.2f} ms")
```

## ğŸ“Š æ•°æ®ç»“æ„

### å•æ¬¡LLMè°ƒç”¨è®°å½•

```python
{
    "trace_id": "uuid",
    "module": "intent_router",
    "model": "qwen-plus",
    "prompt_tokens": 420,
    "completion_tokens": 98,
    "total_tokens": 518,
    "latency_ms": 820.5,
    "timestamp": "2025-01-10 14:32:10",
    "success": True,
    "error": None
}
```

### ç”¨æˆ·è¯·æ±‚çº§åˆ«èšåˆè®°å½•

```python
{
    "trace_id": "uuid",
    "user_query": "è¿™ä¸ªå®¢æˆ·é£é™©é«˜ä¸é«˜ï¼Ÿç°åœ¨æ”¿ç­–è¿˜æ”¯ä¸æ”¯æŒï¼Ÿ",
    "steps": [
        {
            "module": "intent_router",
            "tokens": 518,
            "latency_ms": 820.5
        },
        {
            "module": "policy_rag_answer",
            "tokens": 1240,
            "latency_ms": 1520.3
        }
    ],
    "total_tokens": 1758,
    "total_latency_ms": 2340.8,
    "timestamp": "2025-01-10 14:32:15",
    "success": True
}
```

## ğŸ”§ APIå‚è€ƒ

### MonitorManager

ç›‘æ§ç®¡ç†å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

```python
from src.utils.monitor import get_monitor_manager

manager = get_monitor_manager()

# è·å–å•æ¬¡è°ƒç”¨è®°å½•
call_records = manager.get_call_records(limit=10)  # è·å–æœ€è¿‘10æ¡

# è·å–è¯·æ±‚çº§åˆ«è®°å½•
request_records = manager.get_request_records(limit=10)

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = manager.get_statistics()
print(f"æ€»è°ƒç”¨æ¬¡æ•°: {stats['total_calls']}")
print(f"æ€»Tokenæ•°: {stats['total_tokens']}")
print(f"å¹³å‡æ¯æ¬¡è°ƒç”¨Tokenæ•°: {stats['avg_tokens_per_call']:.2f}")

# å¯¼å‡ºåˆ°JSONæ–‡ä»¶
manager.export_to_json("monitor_records.json")

# æ¸…ç©ºè®°å½•
manager.clear_records()
```

### RequestMonitor

ç”¨æˆ·è¯·æ±‚çº§åˆ«çš„ç›‘æ§å™¨

```python
from src.utils.monitor import RequestMonitor

# åˆ›å»ºç›‘æ§å™¨
monitor = RequestMonitor(user_query="ç”¨æˆ·é—®é¢˜")

# æ·»åŠ æ­¥éª¤
monitor.add_step(module="intent_router", tokens=518, latency_ms=820.5)

# å®Œæˆç›‘æ§
record = monitor.finish(success=True)

# è·å–å½“å‰ç»Ÿè®¡
stats = monitor.get_current_stats()
```

## ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯

```python
from src.utils.monitor import print_statistics

# æ‰“å°ç»Ÿè®¡ä¿¡æ¯
print_statistics()
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
ç›‘æ§ç»Ÿè®¡ä¿¡æ¯
============================================================
æ€»è°ƒç”¨æ¬¡æ•°: 25
æ€»Tokenæ•°: 12580
å¹³å‡æ¯æ¬¡è°ƒç”¨Tokenæ•°: 503.20
å¹³å‡å»¶è¿Ÿ: 1250.50 ms
æ€»è¯·æ±‚æ•°: 5
============================================================
```

## ğŸ”„ é›†æˆåˆ°ç°æœ‰ä»£ç 

### æ›´æ–°router.pyä»¥ä½¿ç”¨è¯·æ±‚çº§åˆ«ç›‘æ§

```python
from src.utils.monitor import RequestMonitor, monitor_step, get_monitor_manager

def route_and_query(question: str, ...):
    # åˆ›å»ºè¯·æ±‚ç›‘æ§å™¨
    request_monitor = RequestMonitor(user_query=question)
    
    try:
        # æ­¥éª¤1ï¼šæ„å›¾è¯†åˆ«
        with monitor_step("intent_router", request_monitor.trace_id):
            intent_result = classify_intent(question)
            # è·å–æœ€è¿‘çš„è°ƒç”¨è®°å½•
            recent = get_monitor_manager().get_call_records(limit=1)
            if recent:
                request_monitor.add_step(
                    module="intent_router",
                    tokens=recent[0]['total_tokens'],
                    latency_ms=recent[0]['latency_ms']
                )
        
        # æ­¥éª¤2ï¼šRAGæŸ¥è¯¢
        with monitor_step("policy_rag_answer", request_monitor.trace_id):
            answer = rag_query(...)
            recent = get_monitor_manager().get_call_records(limit=1)
            if recent:
                request_monitor.add_step(
                    module="policy_rag_answer",
                    tokens=recent[0]['total_tokens'],
                    latency_ms=recent[0]['latency_ms']
                )
        
        # å®Œæˆç›‘æ§
        request_monitor.finish(success=True)
        
        return result
    except Exception as e:
        request_monitor.finish(success=False)
        raise
```

## ğŸ“š ç›¸å…³æ–‡ä»¶

- `src/utils/monitor.py` - ç›‘æ§æ¨¡å—æ ¸å¿ƒä»£ç 
- `src/rag/query.py` - å·²é›†æˆç›‘æ§çš„RAGæŸ¥è¯¢æ¨¡å—
- `src/intent/classification.py` - æ„å›¾è¯†åˆ«æ¨¡å—ï¼ˆå¯é›†æˆç›‘æ§ï¼‰

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **Tokenä¼°ç®—**ï¼šå¯¹äºæœ¬åœ°æ¨¡å‹ï¼Œå¦‚æœæ— æ³•è·å–ç²¾ç¡®tokenæ•°ï¼Œä¼šä½¿ç”¨å­—ç¬¦æ•°ä¼°ç®—ï¼ˆ1 token â‰ˆ 4å­—ç¬¦ï¼‰
2. **æ€§èƒ½å½±å“**ï¼šç›‘æ§åŠŸèƒ½å¯¹æ€§èƒ½å½±å“å¾ˆå°ï¼Œä½†å¤§é‡è°ƒç”¨æ—¶å»ºè®®å®šæœŸæ¸…ç†è®°å½•
3. **å†…å­˜ç®¡ç†**ï¼šç›‘æ§è®°å½•å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œé•¿æ—¶é—´è¿è¡Œå»ºè®®å®šæœŸå¯¼å‡ºå¹¶æ¸…ç†

