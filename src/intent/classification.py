"""
é—®é¢˜ç†è§£ä¸èƒ½åŠ›è·¯ç”±æ¨¡å—
åŠŸèƒ½ï¼š
1. åˆ¤æ–­ç”¨æˆ·è¾“å…¥æ˜¯å¦åŒ…å«å¤šä¸ªè¯­ä¹‰ä¸Šç‹¬ç«‹çš„é—®é¢˜ï¼ˆé—®é¢˜æ‹†åˆ†ï¼‰
2. ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œæ„å›¾è¯†åˆ«ï¼ˆCoTæ€ç»´é“¾æ¨ç†ï¼‰
3. è§£ææ„å›¾ç±»å‹å¹¶é€‰æ‹©å¯¹åº”çš„ç³»ç»Ÿèƒ½åŠ›
4. è·¯ç”±å†³ç­–ï¼ˆRAGæˆ–é¢„æµ‹æ¨¡å—ï¼‰
"""

import os
import sys
import re
import json
from pathlib import Path
from typing import Dict, Optional, Tuple, List
from dataclasses import dataclass
from enum import Enum

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥é…ç½®
from config.prompts import INTENT_CLASSIFICATION_PROMPT, TODAY

# å¯¼å…¥ç›‘æ§æ¨¡å—
from src.utils.llm_monitor import llm_monitor, set_token_info
from src.utils.monitor import extract_token_info_from_response

# ============================================================================
# é…ç½®åŒºåŸŸ
# ============================================================================

# å¤§æ¨¡å‹é…ç½®ï¼ˆä¸rag_query.pyä¿æŒä¸€è‡´ï¼‰
LLM_MODE = os.getenv('LLM_MODE', 'bailian').lower()
DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY', '')
BAILIAN_MODEL = os.getenv('BAILIAN_MODEL', 'qwen-plus')
LOCAL_MODEL_PATH = os.getenv('LOCAL_MODEL_PATH', 'Qwen/Qwen2.5-7B-Instruct')

# ============================================================================
# ä¾èµ–æ£€æŸ¥
# ============================================================================

try:
    from dashscope import Generation
    import dashscope
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False

try:
    from transformers import AutoTokenizer, AutoModelForCausalLM
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# ============================================================================
# æ„å›¾ç±»å‹æšä¸¾
# ============================================================================

class IntentType(Enum):
    """æ„å›¾ç±»å‹æšä¸¾"""
    POLICY_QUERY = "policy_query"           # æ”¿ç­–æŸ¥è¯¢
    SYSTEM_QUERY = "system_query"           # ç³»ç»Ÿæ“ä½œ
    CUSTOMER_ANALYSIS = "customer_analysis" # å®¢æˆ·åˆ†æ
    GENERAL = "general"                      # ä¸€èˆ¬æ€§é—®é¢˜

# ============================================================================
# æ•°æ®ç±»å®šä¹‰
# ============================================================================

@dataclass
class IntentResult:
    """æ„å›¾è¯†åˆ«ç»“æœ"""
    intent: IntentType              # æ„å›¾ç±»å‹
    confidence: float               # ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
    reasoning: str                  # æ¨ç†è¿‡ç¨‹ï¼ˆCoTè¾“å‡ºï¼‰
    route_to: str                   # è·¯ç”±ç›®æ ‡ï¼ˆ'rag_policy'/'rag_system'/'prediction'/'general'ï¼‰
    # å®ä½“ä¿¡æ¯ï¼ˆç”¨äºL2è®°å¿†ï¼‰
    active_domain: List[str] = None  # ä¸šåŠ¡åŸŸåˆ—è¡¨ï¼ˆå¦‚ï¼š['system'], ['policy']ç­‰ï¼‰
    business_object: str = ""       # ä¸šåŠ¡å¯¹è±¡ï¼ˆå¦‚ï¼šæŠ¼å“ã€å®¢æˆ·ç­‰ï¼‰
    operation_stage: str = ""       # æ“ä½œé˜¶æ®µï¼ˆå¦‚ï¼šåˆ›å»ºã€å…¥åº“ã€å®¡æ‰¹ç­‰ï¼‰

# ============================================================================
# å…¨å±€å˜é‡ï¼ˆæ¨¡å‹ç¼“å­˜ï¼‰
# ============================================================================

_local_llm_model = None
_local_llm_tokenizer = None

# ============================================================================
# å¤§æ¨¡å‹è°ƒç”¨ï¼ˆå¤ç”¨rag_query.pyçš„é€»è¾‘ï¼‰
# ============================================================================

def load_local_llm_model(model_path: str = None):
    """åŠ è½½æœ¬åœ°LLMæ¨¡å‹ï¼ˆå…¨å±€ç¼“å­˜ï¼‰"""
    global _local_llm_model, _local_llm_tokenizer
    
    if _local_llm_model is not None:
        return _local_llm_model, _local_llm_tokenizer
    
    if not TRANSFORMERS_AVAILABLE:
        raise Exception("transformersæœªå®‰è£…")
    
    if model_path is None:
        model_path = LOCAL_MODEL_PATH
    
    print(f"  æ­£åœ¨åŠ è½½æœ¬åœ°LLMæ¨¡å‹: {model_path}")
    
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        
        use_cpu = os.getenv('FORCE_CPU', 'false').lower() == 'true'
        if use_cpu:
            device_map = 'cpu'
        elif torch.cuda.is_available():
            device_map = 'auto'
        else:
            device_map = 'cpu'
        
        model = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True,
            device_map=device_map,
            torch_dtype=torch.float16 if device_map != 'cpu' else torch.float32
        )
        model.eval()
        
        _local_llm_model = model
        _local_llm_tokenizer = tokenizer
        
        print(f"  âœ“ æœ¬åœ°LLMæ¨¡å‹åŠ è½½æˆåŠŸ")
        return model, tokenizer
        
    except Exception as e:
        raise Exception(f"æœ¬åœ°LLMæ¨¡å‹åŠ è½½å¤±è´¥: {e}")


def call_local_llm(prompt: str, max_length: int = 500, module: str = "intent_classification") -> str:
    """
    è°ƒç”¨æœ¬åœ°LLMæ¨¡å‹
    
    å‚æ•°:
        prompt: æç¤ºè¯
        max_length: æœ€å¤§ç”Ÿæˆé•¿åº¦
        module: æ¨¡å—åç§°ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ä»¥å…¼å®¹æ—§ä»£ç ï¼‰
    
    è¿”å›:
        str: æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
    """
    model, tokenizer = load_local_llm_model()
    
    # æ„å»ºæç¤ºè¯ï¼ˆQwen2.5æ ¼å¼ï¼‰
    formatted_prompt = f"<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n"
    
    # Tokenizeï¼ˆè·å–å®é™…tokenæ•°ï¼‰
    inputs = tokenizer.encode(formatted_prompt, return_tensors='pt')
    prompt_tokens = inputs.shape[1]  # è·å–å®é™…tokenæ•°
    
    device = next(model.parameters()).device
    inputs = inputs.to(device)
    
    # ç”Ÿæˆ
    with torch.no_grad():
        outputs = model.generate(
            inputs,
            max_length=inputs.shape[1] + max_length,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )
    
    # è§£ç 
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # æå–assistantçš„å›å¤
    if '<|im_start|>assistant\n' in generated_text:
        response = generated_text.split('<|im_start|>assistant\n')[-1]
        response = response.split('<|im_end|>')[0].strip()
    else:
        response = generated_text[len(formatted_prompt):].strip()
    
    # è®¡ç®—completion tokensï¼ˆç”Ÿæˆçš„æ€»tokenæ•°å‡å»è¾“å…¥çš„tokenæ•°ï¼‰
    # outputs.shape[1] æ˜¯å®Œæ•´åºåˆ—é•¿åº¦ï¼ˆè¾“å…¥+ç”Ÿæˆï¼‰ï¼Œprompt_tokens æ˜¯è¾“å…¥é•¿åº¦
    # å·®å€¼å°±æ˜¯ç”Ÿæˆçš„tokenæ•°ï¼ˆä½¿ç”¨max(0, ...)é˜²æ­¢è´Ÿæ•°ï¼‰
    completion_tokens = max(0, outputs.shape[1] - prompt_tokens)
    
    # è®¾ç½®tokenä¿¡æ¯åˆ°çº¿ç¨‹æœ¬åœ°å­˜å‚¨ï¼ˆä¾›ç›‘æ§è£…é¥°å™¨ä½¿ç”¨ï¼‰
    set_token_info(prompt_tokens, completion_tokens)
    
    return response


def call_bailian_api(prompt: str, module: str = "intent_classification") -> str:
    """
    è°ƒç”¨ç™¾ç‚¼API
    
    å‚æ•°:
        prompt: æç¤ºè¯
        module: æ¨¡å—åç§°ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ä»¥å…¼å®¹æ—§ä»£ç ï¼‰
    
    è¿”å›:
        str: æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
    """
    if not DASHSCOPE_AVAILABLE:
        raise Exception("dashscopeæœªå®‰è£…")
    
    if not DASHSCOPE_API_KEY:
        raise ValueError("ç™¾ç‚¼APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
    
    dashscope.api_key = DASHSCOPE_API_KEY
    
    response = Generation.call(
        model=BAILIAN_MODEL,
        prompt=prompt,
        temperature=0.7,
        max_tokens=500,
        result_format='message'
    )
    
    if response.status_code == 200:
        # æå–tokenä¿¡æ¯ï¼ˆä»å“åº”å¯¹è±¡ä¸­ï¼‰
        prompt_tokens = 0
        completion_tokens = 0
        try:
            token_info = extract_token_info_from_response(response, BAILIAN_MODEL)
            prompt_tokens = token_info.get('prompt_tokens', 0)
            completion_tokens = token_info.get('completion_tokens', 0)
        except Exception:
            # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼0
            pass
        
        content = None
        if 'output' in response:
            output = response['output']
            if 'choices' in output and len(output['choices']) > 0:
                message = output['choices'][0].get('message', {})
                if 'content' in message:
                    content = message['content'].strip()
            if not content and 'text' in output:
                content = output['text'].strip()
        
        if not content and 'text' in response:
            content = response['text'].strip()
        if not content and 'content' in response:
            content = response['content'].strip()
        
        if content:
            # è®¾ç½®tokenä¿¡æ¯åˆ°çº¿ç¨‹æœ¬åœ°å­˜å‚¨ï¼ˆä¾›ç›‘æ§è£…é¥°å™¨ä½¿ç”¨ï¼‰
            set_token_info(prompt_tokens, completion_tokens)
            return content
    
    error_msg = f"ç™¾ç‚¼APIè°ƒç”¨å¤±è´¥: {response.status_code}"
    if hasattr(response, 'message'):
        error_msg += f" - {response.message}"
    raise Exception(error_msg)


def call_llm(prompt: str, mode: str = None, module: str = "intent_classification") -> str:
    """
    è°ƒç”¨å¤§æ¨¡å‹ï¼ˆç»Ÿä¸€æ¥å£ï¼Œå¸¦ç›‘æ§ï¼‰
    
    å‚æ•°:
        prompt: æç¤ºè¯
        mode: è°ƒç”¨æ¨¡å¼ï¼ˆ'bailian' æˆ– 'local'ï¼‰ï¼Œå¦‚æœä¸ºNoneï¼Œä½¿ç”¨å…¨å±€é…ç½®
        module: æ¨¡å—åç§°ï¼ˆç”¨äºç›‘æ§ï¼‰
    
    è¿”å›:
        str: æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
    """
    if mode is None:
        mode = LLM_MODE
    
    if mode == 'local':
        return call_local_llm(prompt, module=module)
    else:
        return call_bailian_api(prompt, module=module)

# ============================================================================
# æ„å›¾è¯†åˆ«æ ¸å¿ƒå‡½æ•°
# ============================================================================

def parse_intent_and_entities_from_response(response: str) -> Tuple[IntentType, str, Dict]:
    """
    ä»æ¨¡å‹å“åº”ä¸­è§£ææ„å›¾ç±»å‹å’Œå®ä½“ä¿¡æ¯ï¼ˆæ”¯æŒJSONæ ¼å¼å’Œæ–‡æœ¬æ ¼å¼ï¼‰
    
    å‚æ•°:
        response: æ¨¡å‹å“åº”æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯JSONæ•°ç»„æˆ–åŒ…å«CoTæ¨ç†è¿‡ç¨‹çš„æ–‡æœ¬ï¼‰
    
    è¿”å›:
        Tuple[IntentType, str, Dict]: (æ„å›¾ç±»å‹, æ¨ç†è¿‡ç¨‹, å®ä½“ä¿¡æ¯å­—å…¸)
        å®ä½“ä¿¡æ¯å­—å…¸åŒ…å«ï¼šactive_domain, business_object, operation_stage
    """
    # é»˜è®¤å®ä½“ä¿¡æ¯ï¼ˆä¸å†åŒ…å«active_domainï¼Œç”±è§„åˆ™æ˜ å°„ï¼‰
    default_entities = {
        'business_object': '',
        'operation_stage': ''
    }
    
    # è°ƒè¯•ï¼šé¦–å…ˆè¾“å‡ºåŸå§‹å“åº”
    print(f"  ğŸ” [parse_intent_and_entities_from_response] å¼€å§‹è§£æï¼Œå“åº”é•¿åº¦: {len(response) if response else 0}")
    if response:
        print(f"  ğŸ” [parse_intent_and_entities_from_response] å“åº”å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰: {response[:500]}...")
    else:
        print(f"  âš  [parse_intent_and_entities_from_response] å“åº”ä¸ºç©ºï¼")
        return IntentType.GENERAL, "", default_entities
    
    # æ¸…ç†å“åº”æ–‡æœ¬
    original_response = response
    response = response.strip()
    
    # æ–¹æ³•1ï¼šå°è¯•è§£æJSONæ ¼å¼ï¼ˆæ ¹æ®æç¤ºè¯ï¼Œåº”è¯¥è¿”å›JSONæ•°ç»„ï¼‰
    try:
        # å°è¯•æå–JSONéƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«åœ¨ä»£ç å—æˆ–å…¶ä»–æ–‡æœ¬ä¸­ï¼‰
        json_match = re.search(r'\[.*\]', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            # å°è¯•æ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°
            json_str = json_str.strip()
            if json_str.startswith('```'):
                # ç§»é™¤ä»£ç å—æ ‡è®°
                lines = json_str.split('\n')
                json_str = '\n'.join([line for line in lines if not line.strip().startswith('```')])
            json_str = json_str.strip()
            
            # å°è¯•è§£æJSON
            try:
                parsed_data = json.loads(json_str)
                print(f"  âœ“ JSONè§£ææˆåŠŸ")
            except json.JSONDecodeError as json_err:
                print(f"  âš  JSONè§£æå¤±è´¥: {json_err}")
                raise
            
            # ç¡®ä¿æ˜¯æ•°ç»„æ ¼å¼
            if isinstance(parsed_data, list) and len(parsed_data) > 0:
                # è·å–ç¬¬ä¸€ä¸ªå…ƒç´ çš„å®Œæ•´ä¿¡æ¯
                first_item = parsed_data[0]
                if isinstance(first_item, dict) and 'intent' in first_item:
                    intent_str = first_item['intent'].lower()
                    
                    # æ˜ å°„åˆ°IntentType
                    intent_mapping = {
                        'policy_query': IntentType.POLICY_QUERY,
                        'system_query': IntentType.SYSTEM_QUERY,
                        'customer_analysis': IntentType.CUSTOMER_ANALYSIS,
                        'general': IntentType.GENERAL
                    }
                    
                    intent_type = intent_mapping.get(intent_str, IntentType.GENERAL)
                    
                    # æå–å®ä½“ä¿¡æ¯ï¼ˆä¸å†æå–active_domainï¼Œç”±è§„åˆ™æ˜ å°„ï¼‰
                    entities = {
                        'business_object': first_item.get('business_object', ''),
                        'operation_stage': first_item.get('operation_stage', '')
                    }
                    
                    return intent_type, original_response, entities
                else:
                    print(f"  âš  JSONæ ¼å¼é”™è¯¯ï¼šç¬¬ä¸€ä¸ªå…ƒç´ ä¸æ˜¯å­—å…¸æˆ–ç¼ºå°‘'intent'å­—æ®µ")
    except Exception as e:
        print(f"  âš  JSONè§£æå¤±è´¥ï¼ˆæ–¹æ³•1ï¼‰: {e}ï¼Œå°è¯•å…¶ä»–è§£ææ–¹æ³•")
    
    # æ–¹æ³•2ï¼šå°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”ä¸ºJSON
    try:
        parsed_data = json.loads(response)
        if isinstance(parsed_data, list) and len(parsed_data) > 0:
            first_item = parsed_data[0]
            if isinstance(first_item, dict) and 'intent' in first_item:
                intent_str = first_item['intent'].lower()
                intent_mapping = {
                    'policy_query': IntentType.POLICY_QUERY,
                    'system_query': IntentType.SYSTEM_QUERY,
                    'customer_analysis': IntentType.CUSTOMER_ANALYSIS,
                    'general': IntentType.GENERAL
                }
                intent_type = intent_mapping.get(intent_str, IntentType.GENERAL)
                
                # æå–å®ä½“ä¿¡æ¯ï¼ˆä¸å†æå–active_domainï¼Œç”±è§„åˆ™æ˜ å°„ï¼‰
                entities = {
                    'business_object': first_item.get('business_object', ''),
                    'operation_stage': first_item.get('operation_stage', '')
                }
                
                return intent_type, original_response, entities
    except Exception as e:
        print(f"  âš  JSONè§£æå¤±è´¥ï¼ˆæ–¹æ³•2ï¼‰: {e}")
    
    # æ–¹æ³•3ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼ˆé™çº§æ–¹æ¡ˆï¼Œåªè§£ææ„å›¾ï¼Œå®ä½“ä¿¡æ¯ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    intent_patterns = {
        IntentType.POLICY_QUERY: [
            r'policy_query',
            r'æ”¿ç­–æŸ¥è¯¢',
            r'æ”¿ç­–ç±»',
            r'ç›‘ç®¡è¦æ±‚',
            r'æ”¿ç­–è§„å®š'
        ],
        IntentType.SYSTEM_QUERY: [
            r'system_query',
            r'ç³»ç»Ÿæ“ä½œ',
            r'ç³»ç»Ÿç±»',
            r'å¦‚ä½•æ“ä½œ',
            r'åŠŸèƒ½ä½¿ç”¨'
        ],
        IntentType.CUSTOMER_ANALYSIS: [
            r'customer_analysis',
            r'å®¢æˆ·åˆ†æ',
            r'å®¢æˆ·é£é™©',
            r'è´·æ¬¾æ„å‘',
            r'å®¢æˆ·è¯„ä¼°'
        ],
        IntentType.GENERAL: [
            r'general',
            r'ä¸€èˆ¬æ€§',
            r'é€šç”¨'
        ]
    }
    
    # æŸ¥æ‰¾åŒ¹é…çš„æ„å›¾ç±»å‹
    for intent_type, patterns in intent_patterns.items():
        for pattern in patterns:
            if re.search(pattern, response, re.IGNORECASE):
                return intent_type, response, default_entities
    
    # æ–¹æ³•4ï¼šé»˜è®¤è¿”å›general
    return IntentType.GENERAL, response, default_entities


def parse_intent_from_response(response: str) -> Tuple[IntentType, str]:
    """
    ä»æ¨¡å‹å“åº”ä¸­è§£ææ„å›¾ç±»å‹ï¼ˆæ”¯æŒJSONæ ¼å¼å’Œæ–‡æœ¬æ ¼å¼ï¼‰
    å…¼å®¹æ—§ç‰ˆæœ¬ï¼Œè°ƒç”¨æ–°å‡½æ•°å¹¶åªè¿”å›æ„å›¾å’Œæ¨ç†è¿‡ç¨‹
    
    å‚æ•°:
        response: æ¨¡å‹å“åº”æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯JSONæ•°ç»„æˆ–åŒ…å«CoTæ¨ç†è¿‡ç¨‹çš„æ–‡æœ¬ï¼‰
    
    è¿”å›:
        Tuple[IntentType, str]: (æ„å›¾ç±»å‹, æ¨ç†è¿‡ç¨‹)
    
    æ³¨æ„ï¼šæ­¤æ–¹æ³•å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨ parse_intent_and_entities_from_response
    ä¿ç•™æ­¤æ–¹æ³•ä»…ç”¨äºå‘åå…¼å®¹
    """
    intent, reasoning, _ = parse_intent_and_entities_from_response(response)
    return intent, reasoning


@llm_monitor(module="intent_classification")
def classify_intent(question: str, use_cot: bool = True) -> IntentResult:
    """
    é—®é¢˜ç†è§£ä¸æ„å›¾è¯†åˆ«ï¼ˆæ”¯æŒCoTæ€ç»´é“¾æ¨ç†ï¼‰
    
    åŠŸèƒ½ï¼š
    1. åˆ¤æ–­ç”¨æˆ·è¾“å…¥æ˜¯å¦åŒ…å«å¤šä¸ªè¯­ä¹‰ä¸Šç‹¬ç«‹çš„é—®é¢˜
    2. å¦‚æœåªæœ‰ä¸€ä¸ªæ¸…æ™°é—®é¢˜ï¼Œä¿æŒåŸé—®é¢˜ä¸æ‹†åˆ†
    3. åªæœ‰åœ¨ç”¨æˆ·æ˜ç¡®æå‡ºå¤šä¸ªä¸åŒç›®æ ‡æ—¶ï¼Œæ‰æ‹†åˆ†ä¸ºå¤šä¸ªå­é—®é¢˜
    4. ä¸ºæ¯ä¸ªé—®é¢˜åˆ¤æ–­å…¶æ„å›¾ç±»å‹ï¼Œå¹¶é€‰æ‹©å¯¹åº”çš„ç³»ç»Ÿèƒ½åŠ›
    
    å‚æ•°:
        question: ç”¨æˆ·é—®é¢˜
        use_cot: æ˜¯å¦ä½¿ç”¨CoTæ€ç»´é“¾æ¨ç†ï¼ˆé»˜è®¤Trueï¼‰
    
    è¿”å›:
        IntentResult: æ„å›¾è¯†åˆ«ç»“æœï¼ˆåŒ…å«é—®é¢˜æ‹†åˆ†ä¿¡æ¯ï¼‰
    """
    # æ„å»ºæç¤ºè¯ï¼ˆåŒ…å«æ—¥æœŸä¿¡æ¯ï¼‰
    prompt = INTENT_CLASSIFICATION_PROMPT.format(question=question, today=TODAY)
    
    try:
        # è°ƒç”¨å¤§æ¨¡å‹
        print(f"  ğŸ“ æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œæ„å›¾è¯†åˆ«...")
        response = call_llm(prompt)
        print(f"  âœ“ LLMè°ƒç”¨å®Œæˆï¼Œå“åº”é•¿åº¦: {len(response) if response else 0}")
        
        # è°ƒè¯•ï¼šè¾“å‡ºLLMçš„åŸå§‹å“åº”ï¼ˆä»…å‰500å­—ç¬¦ï¼Œé¿å…è¾“å‡ºè¿‡é•¿ï¼‰
        if response:
            if len(response) > 500:
                print(f"  ğŸ“ LLMåŸå§‹å“åº”ï¼ˆå‰500å­—ç¬¦ï¼‰: {response[:500]}...")
            else:
                print(f"  ğŸ“ LLMåŸå§‹å“åº”: {response}")
        else:
            print(f"  âš  LLMè¿”å›çš„å“åº”ä¸ºç©ºï¼")
            raise ValueError("LLMè¿”å›çš„å“åº”ä¸ºç©º")
        
        # è§£ææ„å›¾ç±»å‹å’Œå®ä½“ä¿¡æ¯
        print(f"  ğŸ” å¼€å§‹è§£ææ„å›¾ç±»å‹å’Œå®ä½“ä¿¡æ¯...")
        intent, reasoning, entities = parse_intent_and_entities_from_response(response)
        print(f"  âœ“ æ„å›¾è§£æå®Œæˆï¼Œæ„å›¾ç±»å‹: {intent.value}")
        print(f"  âœ“ å®ä½“ä¿¡æ¯: {entities}")
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç®€åŒ–ç‰ˆï¼šåŸºäºå“åº”ä¸­æ˜¯å¦æ˜ç¡®åŒ…å«æ„å›¾ç±»å‹ï¼‰
        confidence = 0.8 if intent != IntentType.GENERAL else 0.5
        
        # ç¡®å®šè·¯ç”±ç›®æ ‡
        route_mapping = {
            IntentType.POLICY_QUERY: 'rag_policy',
            IntentType.SYSTEM_QUERY: 'rag_system',
            IntentType.CUSTOMER_ANALYSIS: 'prediction',
            IntentType.GENERAL: 'general'
        }
        route_to = route_mapping.get(intent, 'general')
        
        # æ ¹æ®intentç±»å‹ç›´æ¥æ˜ å°„active_domainï¼ˆè§„åˆ™æ˜ å°„ï¼Œä¸éœ€è¦LLMæŠ½å–ï¼‰
        # è¿™æ ·å¯ä»¥æé«˜å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ï¼Œå‡å°‘LLMå·¥ä½œé‡
        domain_mapping = {
            IntentType.POLICY_QUERY: ['policy'],
            IntentType.SYSTEM_QUERY: ['system'],
            IntentType.CUSTOMER_ANALYSIS: ['risk'],
            IntentType.GENERAL: []
        }
        active_domain = domain_mapping.get(intent, [])
        
        return IntentResult(
            intent=intent,
            confidence=confidence,
            reasoning=reasoning,
            route_to=route_to,
            active_domain=active_domain,  # ä½¿ç”¨è§„åˆ™æ˜ å°„ï¼Œè€Œä¸æ˜¯LLMæŠ½å–
            business_object=entities.get('business_object', ''),
            operation_stage=entities.get('operation_stage', '')
        )
        
    except Exception as e:
        # æ”¹è¿›é”™è¯¯å¤„ç†ï¼šè¾“å‡ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_type = type(e).__name__
        error_msg = str(e)
        print(f"  âš  é—®é¢˜ç†è§£ä¸æ„å›¾è¯†åˆ«å¤±è´¥: {error_type}: {error_msg}")
        
        # è¾“å‡ºå®Œæ•´çš„å¼‚å¸¸ä¿¡æ¯ï¼ˆåŒ…æ‹¬æ‰€æœ‰å±æ€§ï¼‰
        print(f"  âš  å¼‚å¸¸ç±»å‹: {error_type}")
        print(f"  âš  å¼‚å¸¸æ¶ˆæ¯: {error_msg}")
        print(f"  âš  å¼‚å¸¸å‚æ•°: {getattr(e, 'args', 'N/A')}")
        
        # å¦‚æœæ˜¯JSONè§£æç›¸å…³çš„é”™è¯¯ï¼Œè¾“å‡ºæ›´å¤šè°ƒè¯•ä¿¡æ¯
        if 'sub_question' in error_msg or 'JSON' in error_msg or 'json' in error_msg or 'JSONDecodeError' in error_type:
            print(f"  âš  å¯èƒ½æ˜¯JSONè§£æé”™è¯¯ï¼Œé”™è¯¯è¯¦æƒ…: {error_msg}")
            print(f"  âš  ç”¨æˆ·é—®é¢˜: {question}")
            import traceback
            print(f"  âš  å®Œæ•´é”™è¯¯å †æ ˆ:")
            traceback.print_exc()
        
        # é™çº§å¤„ç†ï¼šä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…
        return fallback_intent_classification(question)


def fallback_intent_classification(question: str) -> IntentResult:
    """
    é™çº§å¤„ç†ï¼šåŸºäºå…³é”®è¯çš„ç®€å•æ„å›¾è¯†åˆ«
    
    å‚æ•°:
        question: ç”¨æˆ·é—®é¢˜
    
    è¿”å›:
        IntentResult: æ„å›¾è¯†åˆ«ç»“æœ
    """
    question_lower = question.lower()
    
    # æ”¿ç­–æŸ¥è¯¢å…³é”®è¯ï¼ˆç§»é™¤é€šç”¨ä¸šåŠ¡æœ¯è¯­ï¼Œåªä¿ç•™æ˜ç¡®æŒ‡å‘æ”¿ç­–çš„å…³é”®è¯ï¼‰
    # æ³¨æ„ï¼šç§»é™¤äº†"æˆä¿¡"ã€"ä¿¡è´·"ã€"é“¶è¡Œ"ç­‰é€šç”¨æœ¯è¯­ï¼Œå› ä¸ºè¿™äº›è¯åœ¨ç³»ç»Ÿæ“ä½œé—®é¢˜ä¸­ä¹Ÿä¼šå‡ºç°
    policy_keywords = [
        'æ”¿ç­–', 'ç›‘ç®¡', 'è§„å®š', 'è¦æ±‚', 'æ¡æ¬¾', 'è€ƒæ ¸', 'æ ‡å‡†', 'åˆè§„',
        'æ³¨å†Œèµ„æœ¬', 'èµ„æœ¬è¦æ±‚', 
        'ç›‘ç®¡è¦æ±‚', 'æ”¿ç­–è§„å®š', 'åˆ¶åº¦', 'åŠæ³•', 'é€šçŸ¥', 'æ„è§', 'æŒ‡å¼•'
    ]
    
    # ç³»ç»Ÿæ“ä½œå…³é”®è¯ï¼ˆéœ€è¦æ˜ç¡®åŒ…å«"ç³»ç»Ÿ"æˆ–"å¦‚ä½•æ“ä½œ"ç­‰ï¼‰
    # æ³¨æ„ï¼šå¢åŠ äº†"å¦‚ä½•åœ¨"ã€"æ€ä¹ˆåœ¨"ç­‰å¸¸è§ç³»ç»Ÿæ“ä½œé—®æ³•
    system_keywords = [
        'ç³»ç»Ÿ', 'å¦‚ä½•æ“ä½œ', 'æ€ä¹ˆæ“ä½œ', 'æ“ä½œæ­¥éª¤', 'æ“ä½œæµç¨‹', 'åŠŸèƒ½ä½¿ç”¨',
        'å¦‚ä½•ä½¿ç”¨', 'æ€ä¹ˆä½¿ç”¨', 'ç³»ç»ŸåŠŸèƒ½', 'ç³»ç»ŸæŸ¥è¯¢', 'ç³»ç»Ÿç”³è¯·',
        'å¦‚ä½•åœ¨', 'æ€ä¹ˆåœ¨', 'å¦‚ä½•æŸ¥è¯¢', 'æ€ä¹ˆæŸ¥è¯¢', 'å¦‚ä½•ç”³è¯·', 'æ€ä¹ˆç”³è¯·'
    ]
    
    # å®¢æˆ·åˆ†æå…³é”®è¯
    customer_keywords = [
        'é£é™©', 'é¢„æµ‹', 'åˆ†æ', 'è¯„ä¼°', 'æ„å‘', 'è¶‹åŠ¿', 'è´·æ¬¾éœ€æ±‚',
        'å®¢æˆ·é£é™©', 'é£é™©è¯„ä¼°', 'å®¢æˆ·åˆ†æ', 'å®¢æˆ·è¯„ä¼°'
    ]
    
    # è®¡ç®—åŒ¹é…åˆ†æ•°ï¼ˆæƒé‡å¹³å‡ï¼Œæ‰€æœ‰ç±»åˆ«æƒé‡ç›¸åŒï¼‰
    # æ³¨æ„ï¼šæ‰€æœ‰å…³é”®è¯æƒé‡ç»Ÿä¸€ä¸º1ï¼Œç¡®ä¿å…¬å¹³åŒ¹é…
    policy_score = sum(1 if kw in question_lower else 0 for kw in policy_keywords)
    system_score = sum(1 if kw in question_lower else 0 for kw in system_keywords)
    customer_score = sum(1 if kw in question_lower else 0 for kw in customer_keywords)
    
    # åˆ¤æ–­æ„å›¾ç±»å‹ï¼ˆæƒé‡å¹³å‡åçš„åˆ¤æ–­é€»è¾‘ï¼šæŒ‰å¾—åˆ†é«˜ä½åˆ¤æ–­ï¼Œå¾—åˆ†ç›¸åŒæ—¶æŒ‰ä¼˜å…ˆçº§ï¼‰
    # ä¼˜å…ˆçº§ï¼šç³»ç»ŸæŸ¥è¯¢ > æ”¿ç­–æŸ¥è¯¢ > å®¢æˆ·åˆ†æ > é€šç”¨
    max_score = max(policy_score, system_score, customer_score)
    
    if max_score == 0:
        # æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å…³é”®è¯ï¼Œè¿”å›é€šç”¨ç±»å‹
        intent = IntentType.GENERAL
        route_to = 'general'
        confidence = 0.4
    elif system_score == max_score:
        # ç³»ç»Ÿå¾—åˆ†æœ€é«˜ï¼Œåˆ¤æ–­ä¸ºç³»ç»ŸæŸ¥è¯¢
        intent = IntentType.SYSTEM_QUERY
        route_to = 'rag_system'
        confidence = 0.6
    elif policy_score == max_score:
        # æ”¿ç­–å¾—åˆ†æœ€é«˜ï¼Œåˆ¤æ–­ä¸ºæ”¿ç­–æŸ¥è¯¢
        intent = IntentType.POLICY_QUERY
        route_to = 'rag_policy'
        confidence = 0.6
    elif customer_score == max_score:
        # å®¢æˆ·åˆ†æå¾—åˆ†æœ€é«˜ï¼Œåˆ¤æ–­ä¸ºå®¢æˆ·åˆ†æ
        intent = IntentType.CUSTOMER_ANALYSIS
        route_to = 'prediction'
        confidence = 0.6
    else:
        # å…œåº•ï¼šè¿”å›é€šç”¨ç±»å‹
        intent = IntentType.GENERAL
        route_to = 'general'
        confidence = 0.4
    
    # æ ¹æ®intentç±»å‹ç›´æ¥æ˜ å°„active_domainï¼ˆè§„åˆ™æ˜ å°„ï¼‰
    domain_mapping = {
        IntentType.POLICY_QUERY: ['policy'],
        IntentType.SYSTEM_QUERY: ['system'],
        IntentType.CUSTOMER_ANALYSIS: ['risk'],
        IntentType.GENERAL: []
    }
    active_domain = domain_mapping.get(intent, [])
    
    return IntentResult(
        intent=intent,
        confidence=confidence,
        reasoning=f"é™çº§å¤„ç†ï¼šåŸºäºå…³é”®è¯åŒ¹é…ï¼ˆæ”¿ç­–:{policy_score}, ç³»ç»Ÿ:{system_score}, å®¢æˆ·:{customer_score}ï¼‰",
        route_to=route_to,
        active_domain=active_domain,  # ä½¿ç”¨è§„åˆ™æ˜ å°„
        business_object='',  # é™çº§å¤„ç†æ—¶æ— æ³•æŠ½å–ä¸šåŠ¡å¯¹è±¡
        operation_stage=''   # é™çº§å¤„ç†æ—¶æ— æ³•æŠ½å–æ“ä½œé˜¶æ®µ
    )

# ============================================================================
# è·¯ç”±å†³ç­–
# ============================================================================

def route_query(intent_result: IntentResult, question: str) -> Dict:
    """
    æ ¹æ®æ„å›¾è¯†åˆ«ç»“æœè¿›è¡Œè·¯ç”±å†³ç­–
    
    å‚æ•°:
        intent_result: æ„å›¾è¯†åˆ«ç»“æœ
        question: ç”¨æˆ·é—®é¢˜
    
    è¿”å›:
        Dict: è·¯ç”±ä¿¡æ¯
    """
    route_info = {
        'intent': intent_result.intent.value,
        'route_to': intent_result.route_to,
        'confidence': intent_result.confidence,
        'reasoning': intent_result.reasoning,
        'question': question
    }
    
    # æ ¹æ®è·¯ç”±ç›®æ ‡è®¾ç½®å‚æ•°
    if intent_result.route_to == 'rag_policy':
        route_info['domain'] = 'policy'
        route_info['module'] = 'rag'
    elif intent_result.route_to == 'rag_system':
        route_info['domain'] = 'system'
        route_info['module'] = 'rag'
    elif intent_result.route_to == 'prediction':
        route_info['module'] = 'prediction'
    else:
        route_info['module'] = 'general'
    
    return route_info

# ============================================================================
# ä¸»å‡½æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
# ============================================================================

def main():
    """æµ‹è¯•å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='é—®é¢˜ç†è§£ä¸æ„å›¾è¯†åˆ«æµ‹è¯•')
    parser.add_argument('question', type=str, help='ç”¨æˆ·é—®é¢˜')
    parser.add_argument('--no-cot', action='store_true', help='ç¦ç”¨CoTæ€ç»´é“¾æ¨ç†')
    
    args = parser.parse_args()
    
    try:
        print(f"\n{'='*60}")
        print(f"é—®é¢˜ç†è§£ä¸æ„å›¾è¯†åˆ«æµ‹è¯•")
        print(f"{'='*60}")
        print(f"ç”¨æˆ·é—®é¢˜: {args.question}")
        print(f"ä½¿ç”¨CoT: {not args.no_cot}\n")
        
        # è¿›è¡Œé—®é¢˜ç†è§£ä¸æ„å›¾è¯†åˆ«
        result = classify_intent(args.question, use_cot=not args.no_cot)
        
        # è·¯ç”±å†³ç­–
        route_info = route_query(result, args.question)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\n{'='*60}")
        print(f"è¯†åˆ«ç»“æœ")
        print(f"{'='*60}")
        print(f"æ„å›¾ç±»å‹: {result.intent.value}")
        print(f"ç½®ä¿¡åº¦: {result.confidence:.2f}")
        print(f"è·¯ç”±ç›®æ ‡: {result.route_to}")
        print(f"å¤„ç†æ¨¡å—: {route_info['module']}")
        if 'domain' in route_info:
            print(f"åŸŸç±»å‹: {route_info['domain']}")
        
        print(f"\næ¨ç†è¿‡ç¨‹ï¼ˆCoTï¼‰:")
        print(f"{'-'*60}")
        print(result.reasoning)
        
    except Exception as e:
        print(f"\nâŒ é—®é¢˜ç†è§£ä¸æ„å›¾è¯†åˆ«å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

